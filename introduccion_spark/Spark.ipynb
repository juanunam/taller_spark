{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "    $(\"#homeButton\").remove()\n",
       "    $('body').append('<a href=\"#'+$(\"h1,h2,h3:eq(0)\").attr(\"id\")+'\" style=\"position: fixed; bottom: 10px; right: 10px;\" type=\"button\" class=\"btn btn-success btn-circle btn-lg\"><i class=\"glyphicon glyphicon-link\" id=\"homeButton\"></i></a>');\n",
       "    $(\"#MainMenu\").remove()\n",
       "    var menu = \n",
       "      '<div id=\"MainMenu\" style=\"position: fixed; top: 120px; right: 10px; z-index:6; max-height: 500px;\">'+\n",
       "        '<div class=\"list-group panel\" >'+\n",
       "          '<a href=\"#collapseMenu\" class=\"list-group-item list-group-item-success\" data-toggle=\"collapse\" data-parent=\"#MainMenu\">Indíce<i class=\"fa fa-caret-down\"></i></a>'+\n",
       "          '<div class=\"collapse\" id=\"collapseMenu\" style=\"overflow-y: overlay; max-height: 500px;\">'+\n",
       "          '</div>'+\n",
       "        '</div>'+\n",
       "      '</div>'\n",
       "   \n",
       "    var parent = $(menu)\n",
       "    var arrayIds = []\n",
       "    $(\"h1,h2,h3\").attr(\"id\",function(id,Value){\n",
       "        if(Value != \"\"){\n",
       "            var content = (Value.replace(new RegExp('-', 'g'), ' '));\n",
       "            content = \"&nbsp;\".repeat(parseInt($(this).prop(\"tagName\")[1])*2-1) + content;\n",
       "            $(parent).find(\"#collapseMenu\").append('<a href=\"#'+Value+'\" style=\"position:relative;\" class=\"list-group-item\" data-parent=\"#SubMenu1\">'+content+'</a>');\n",
       "        }\n",
       "    })\n",
       "$('body').append(parent)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "    $(\"#homeButton\").remove()\n",
    "    $('body').append('<a href=\"#'+$(\"h1,h2,h3:eq(0)\").attr(\"id\")+'\" style=\"position: fixed; bottom: 10px; right: 10px;\" type=\"button\" class=\"btn btn-success btn-circle btn-lg\"><i class=\"glyphicon glyphicon-link\" id=\"homeButton\"></i></a>');\n",
    "    $(\"#MainMenu\").remove()\n",
    "    var menu = \n",
    "      '<div id=\"MainMenu\" style=\"position: fixed; top: 120px; right: 10px; z-index:6; max-height: 500px;\">'+\n",
    "        '<div class=\"list-group panel\" >'+\n",
    "          '<a href=\"#collapseMenu\" class=\"list-group-item list-group-item-success\" data-toggle=\"collapse\" data-parent=\"#MainMenu\">Indíce<i class=\"fa fa-caret-down\"></i></a>'+\n",
    "          '<div class=\"collapse\" id=\"collapseMenu\" style=\"overflow-y: overlay; max-height: 500px;\">'+\n",
    "          '</div>'+\n",
    "        '</div>'+\n",
    "      '</div>'\n",
    "   \n",
    "    var parent = $(menu)\n",
    "    var arrayIds = []\n",
    "    $(\"h1,h2,h3\").attr(\"id\",function(id,Value){\n",
    "        if(Value != \"\"){\n",
    "            var content = (Value.replace(new RegExp('-', 'g'), ' '));\n",
    "            content = \"&nbsp;\".repeat(parseInt($(this).prop(\"tagName\")[1])*2-1) + content;\n",
    "            $(parent).find(\"#collapseMenu\").append('<a href=\"#'+Value+'\" style=\"position:relative;\" class=\"list-group-item\" data-parent=\"#SubMenu1\">'+content+'</a>');\n",
    "        }\n",
    "    })\n",
    "$('body').append(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    h3{\n",
       "        color:#0094E4;\n",
       "    }\n",
       "    h2{\n",
       "         color:#F28773;\n",
       "    }\n",
       "    h1{\n",
       "         color:#0094E4;\n",
       "    }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    h3{\n",
    "        color:#0094E4;\n",
    "    }\n",
    "    h2{\n",
    "         color:#F28773;\n",
    "    }\n",
    "    h1{\n",
    "         color:#0094E4;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.png\" style=\"width: 20%; margin-left: 70%;\">\n",
    "<img src=\"./images/python.png\">\n",
    "\n",
    "# Spark desde cero\n",
    "\n",
    "Spark es un **general propose data processing engine** (motor de procesamiento de datos de propósito general).\n",
    "Está optimizado para correr en memoria (rápido).\n",
    "Ayuda a procesar datos más rápido que otras alternativas de cómputo distribuido (Map reduce de hadoop).\n",
    "\n",
    "\n",
    "# Generalidades\n",
    "## ¿Qué es el cómputo distribuido?\n",
    "\n",
    "Para manejar grandes cantidades de datos tenemos dos opciones:\n",
    "\n",
    "- Tener una computador muy poderosa y con muchos recursos ($$$)\n",
    "- Tener varias computadoras sencillas (como las que tenemos en casa) conectadas en un cluster.  \n",
    "\n",
    "Por lo general vamos a preferir la segunda opción.\n",
    "\n",
    "Al tener varias computadoras, no tiene sentido poner a trabajar a todas en una misma tarea, sino que lo más eficiente es usar el paradigma divide y vencerás.\n",
    "\n",
    "<img src=\"./images/DIVIDE_Y_VENCERAS.jpg\" style=\"width: 70%\">\n",
    "\n",
    "<img src=\"./images/divide-and-conquer1.png\">\n",
    "\n",
    "http://bigdata.ices.utexas.edu/project/divide-conquer-methods-for-big-data-analytics/\n",
    "\n",
    "## MapReduce\n",
    "\n",
    "Spark se basa en un framework que utiliza la aproximación divide y vencerás el cual se llama MapReduce. MapReduce incluye oras cosas además de la idea de dividir un problema en tareas simples y después conjuntar un problema, incluye cosas como:\n",
    "\n",
    "* Guardado de estados intermedios\n",
    "* identificación de nodos muertos\n",
    "* Balance de cargas\n",
    "* **Etiquetado de resultados para indicar qué resultados van con cuáles.**\n",
    "\n",
    "En suma, MapReduce se trata de:\n",
    "1. Dividir el trabajo en serie (similar que divide y vencerás pero con una relación que puede ser de uno a varios: i.e. puede haber más de un nodo del clúster dedicado a una misma tarea y más de una tarea por nodo del clúster).\n",
    "2. Ejecutar pedazos de trabajo en paralelo (al igual que en la idea de divide y vencerás).\n",
    "3. **Etiquetado de resultados para indicar qué resultados van con cuáles.**\n",
    "4. **Merging serializado para todos los resultados que tienen la misma etiqueta y que puede ser en paralelo para distintas etiquetas.**\n",
    "\n",
    "En python existen las instrucciones **map** y **reduce**. Donde map aplica una función a un arreglo (\"distribuye\"), mientras que reduce toma una instrucción a aplicarse sobre dos elementos y la aplica a todo un arreglo.\n",
    "\n",
    "Para ello, primero necesitamos una función (puede ser una lambda).\n",
    "\n",
    "### map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fahrenheit(T):\n",
    "    return ((float(9)/5)*T + 32)\n",
    "def celsius(T):\n",
    "    return (float(5)/9)*(T-32)\n",
    "temp = (36.5, 37, 37.5,39)\n",
    "\n",
    "F = map(fahrenheit, temp)\n",
    "C = map(celsius, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Celsius = [39.2, 36.5, 37.3, 37.8]\n",
    "Fahrenheit = map(lambda x: (float(9)/5)*x + 32, Celsius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (list(Fahrenheit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué hizo map?\n",
    "\n",
    "### reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "functools.reduce(lambda x,y: x+y, [47,11,42,13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/reduce_diagram.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/MapReduce.jpg\" style=\"width: 70%\">\n",
    "<img src=\"./images/WordCount_MapReduce_Paradigm.PNG\">\n",
    "\n",
    "https://wikis.nyu.edu/download/attachments/74681720/WordCount%20MapReduce%20Paradigm.PNG?version=1&modificationDate=1462902481180&api=v2\n",
    "\n",
    "<div class=\"alert alert-success alert-dismissable\" id=\"def2\">\n",
    "<a href=\"#\" class=\"close\" data-dismiss=\"alert\" aria-label=\"close\">&times;</a>\n",
    " Usar divide y vencerás nos ayuda cuando tenemos muchos datos, <strong>MapReduce es necesario cuando tenemos cantidades masivas de datos! La idea es hacer cómputo masivo con hardware standar.</strong>\n",
    "</div>\n",
    "\n",
    "Además de Spark hay más sistemas basados en MapReduce como el HDFS de HADOOP.\n",
    "El sistema de archivos en Spark sí es HDFS, pero Spark usa memoria distribuida en lugar de sólo archivos distribuidos.\n",
    "\n",
    "## La organización del software de Spark\n",
    "<img src=\"./images/software_spark.png\" style=\"width: 70%\">\n",
    "En un clúster **el master controla todo lo que hacen las demás computadoras** (esclavos). Pero **los esclavos hacen todo el trabajo**.\n",
    "\n",
    "* El **driver** corre en el master.\n",
    "* Los **RDDs** (la estructura de datos principal de Spark) están particionados a través de los workers.\n",
    "* Los **workers** administran estas particiones y sus recursos. En general ha un worker por cada nodo esclavo. Se counica con el clúster manager para decirle qué tanto espacio queda y para qué.\n",
    "* Los ejecutores ejecutan tareas en su partición.Estas tareas llegan de tu programa a través del spark context.\n",
    "* **Caché** es la memoria que está siendo usada para guardar RDD's (memoria local en el nodo esclavo).\n",
    "\n",
    "<img src=\"./images/Software_org_spark_2.png\" style=\"width: 70%\">\n",
    "\n",
    "## El Spark context\n",
    "\n",
    "Se considera el objeto más importante en Spark\n",
    "Conecta a Spark con la infraestructura que usa para correr todos los nodos worker.\n",
    "Sólo se usa uno cada vez que se corre Spark.\n",
    "Es el camino para comunicarse con el sistema de Spark.\n",
    "\n",
    "<img src=\"./images/spark_context.png\" style=\"width: 70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializando el Spark Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initiallizing Spark (just run once) https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sparkcontext-creating-instance-internals.html\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "sc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
