{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "    $(\"#homeButton\").remove()\n",
    "    $('body').append('<a href=\"#'+$(\"h1,h2,h3:eq(0)\").attr(\"id\")+'\" style=\"position: fixed; bottom: 10px; right: 10px;\" type=\"button\" class=\"btn btn-success btn-circle btn-lg\"><i class=\"glyphicon glyphicon-link\" id=\"homeButton\"></i></a>');\n",
    "    $(\"#MainMenu\").remove()\n",
    "    var menu = \n",
    "      '<div id=\"MainMenu\" style=\"position: fixed; top: 120px; right: 10px; z-index:6; max-height: 500px;\">'+\n",
    "        '<div class=\"list-group panel\" >'+\n",
    "          '<a href=\"#collapseMenu\" class=\"list-group-item list-group-item-success\" data-toggle=\"collapse\" data-parent=\"#MainMenu\">Indíce<i class=\"fa fa-caret-down\"></i></a>'+\n",
    "          '<div class=\"collapse\" id=\"collapseMenu\" style=\"overflow-y: overlay; max-height: 500px;\">'+\n",
    "          '</div>'+\n",
    "        '</div>'+\n",
    "      '</div>'\n",
    "   \n",
    "    var parent = $(menu)\n",
    "    var arrayIds = []\n",
    "    $(\"h1,h2,h3\").attr(\"id\",function(id,Value){\n",
    "        if(Value != \"\"){\n",
    "            var content = (Value.replace(new RegExp('-', 'g'), ' '));\n",
    "            content = \"&nbsp;\".repeat(parseInt($(this).prop(\"tagName\")[1])*2-1) + content;\n",
    "            $(parent).find(\"#collapseMenu\").append('<a href=\"#'+Value+'\" style=\"position:relative;\" class=\"list-group-item\" data-parent=\"#SubMenu1\">'+content+'</a>');\n",
    "        }\n",
    "    })\n",
    "$('body').append(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "    h3{\n",
    "        color:#0094E4;\n",
    "    }\n",
    "    h2{\n",
    "         color:#F28773;\n",
    "    }\n",
    "    h1{\n",
    "         color:#0094E4;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.png\" style=\"width: 20%; margin-left: 70%;\">\n",
    "<img src=\"./images/spark.png\" width=\"30%\" height=\"30%\" >\n",
    "\n",
    "<h1>Hitchhiker's Guide to Data Science: Random Forests</h1>\n",
    "\n",
    "## Bibliotecas generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col as c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "El Random Forest (o bosque aleatorio) está constituido por árboles de decisión.\n",
    "\n",
    "Entonces antes de empezar:\n",
    "\n",
    "# Árboles de decisión\n",
    "\n",
    "Un árbol de decisión es una forma gráfica y analítica\n",
    "de representar todos los eventos (sucesos) que\n",
    "pueden surgir a partir de una decisión asumida en\n",
    "cierto momento.\n",
    "\n",
    "Los árboles de decisión ayudan a tomar la decisión “más acertada”,\n",
    "desde un punto de vista probabilístico, ante un\n",
    "abanico de posibles decisiones. Permiten desplegar visualmente un problema y organizar los cálculos que deben realizarse.\n",
    "\n",
    "A partir de un set de datos se puede inferir un árbol de decisión ya sea regresor o clasificador. La diferencia escencial es que un árbol de regresión se usa para predecir respuestas cuantitativas y uno de clasificación respuestas cualitativas.\n",
    "\n",
    "| Clasificación                                                                                                                                                                                    | Regresión                                                                                                                     |\n",
    "|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Predecir respuestas cualitativas                                                                                                                                                                 | Predecir respuestas cuantitativas                                                                                             |\n",
    "| Predecimos que cada observación pertenece a la clase que ocurre más comunmente en la región a la que pertenece.                                                                                  | La respuesta predicha está dada por la respuesta promedio de las observaciones de entrenamiento que pertenecen al mismo nodo. |\n",
    "| Por lo general nos interesa no  sólo la clase (target) que pertenece a un nodo terminal, sino también las proporciones de clases de las  observaciones de entreenamiento que  caen en esa región |                                                                                                                               |\n",
    "\n",
    "Para fines de fines de este mini curso, nos concentraremos en el modo clasificador.\n",
    "\n",
    "\n",
    "## Ventajas\n",
    "* Pueden usarse para clasificación y regresión\n",
    "* Son fáciles de interpretar\n",
    "* Pueden manejar datos categóricos\n",
    "* Por lo general no requieren escalar los datos\n",
    "* Pueden capturar no linearidades e interacciones entre features\n",
    "\n",
    "## Componentes\n",
    "\n",
    "<div class=\"alert alert-warning\"><strong>Nodo de decisión</strong><br>\n",
    "Indica que una decisón debe tomarse en el proceso, en general (no siempre) se representa con un cuadro\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\"><strong>Nodo de probabilidad</strong><br>\n",
    "Indica que en ese punto del proceso ocurre un evento aleatorio. Suele representarse con un círculo\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\"><strong>Rama</strong><br>\n",
    "Nos muestra los distintos caminos que se pueden emprender cuando se toma una decisión u ocurre un evento aleatorio, en general se representa con flechas\n",
    "</div>\n",
    "\n",
    "<img src=\"./images/arbol_d_decision.png\">\n",
    "\n",
    "## Pasos para construir un Árbol de Decisión\n",
    "* Definir el problema.\n",
    "* Dibujar el árbol de decisión.\n",
    "* Asignar probabilidades a los eventos aleatorios.\n",
    "* Estimar los resultados para cada combinación posible de alternativas.\n",
    "* Resolver el problema obteniendo como solución la ruta más óptima.\n",
    "\n",
    "### Ejemplo:\n",
    "<div class=\"alert alert-success alert-dismissable\" id=\"def2\">\n",
    "<a href=\"#\" class=\"close\" data-dismiss=\"alert\" aria-label=\"close\">&times;</a><strong>\n",
    "Suponiendo que nuestro problema es decidir si debemos conceder o no un préstamo...</strong>\n",
    "</div>\n",
    "\n",
    "<img src=\"./images/arbol_prestamo.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un ejemplo en sklearn y python\n",
    "\n",
    "**NOTA, NO ES EL OBJETIVO DE ESTE CURSO APRENDER SKLEARN, PERO ES VISULAMENTE ÚTIL PARA ENTENDER LO QUE QUEREMOS HACER**\n",
    "\n",
    "**Problema:** Queremos predecir la especie de una flor iris como setosa, versicolor o virginica con datos de la longitud de sus pétalos y sépalos. \n",
    "\n",
    "<img src=\"./images/petal_sepal.png\">\n",
    "\n",
    "<img src=\"./images/iris-flowers.png\">\n",
    "\n",
    "1. Cargamos el iris data set y el clasificador por árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris= load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "#data1\n",
    "#iris.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llamamos el clasificador de árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = iris.data[: ,2:]\n",
    "y = iris.target\n",
    "\n",
    "tree_clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacemos la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_graphviz(\n",
    "    tree_clf,\n",
    "    out_file = \"./images/iris_tree.dot\",\n",
    "    feature_names = iris.feature_names[2:],\n",
    "    class_names = iris.target_names,\n",
    "    rounded = True,\n",
    "    filled = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/iris_tree.png\">\n",
    "\n",
    "* **samples:** ¿Para cuántas instancias del conjunto de entrenamiento aplica esta regla?\n",
    "Por ejemplo 50 instancias tienen un ancho de pétalo menor o igual a 0.8.\n",
    "* **value:** Para cuántas instancias del conjunto de entrenamiento de cada clase aplica este nodo.\n",
    "* **gini:** (No confundir con Gini score) Es una medida de la impureza del nodo. Un nodo es puro (gini=0), si todas las instancias del entrenamiento para las que aplica son de la misma clase.\n",
    "\n",
    "Impureza de Gini para el iésimo nodo:\n",
    "\n",
    "$G_i = 1- \\sum_{k=1}^{n}p_{i,k}^2$\n",
    "\n",
    "donde:\n",
    "\n",
    "$p_{i,k}$ Es el cociente de los \"values\" de cada clase entre el \"samples\" del nodo i.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "En el nodo de la izquierda del segundo nivel\n",
    "\n",
    "$G_i = 1- ((\\frac{0}{54})^2 + (\\frac{49}{54})^2 + (\\frac{5}{54})^2)$\n",
    "\n",
    "**Nota:** Gini no es la única medida de pureza.\n",
    "\n",
    "### Para hacer predicciones con el modelo:\n",
    "\n",
    "1.Nos situamos en el nodo base (profundidad = 0) hasta arriba. Ahí preguntamos si los pétalos tienen cierta característica (en este caso una ancho de pétalo menor o igual que 0.8 cm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/iris_tree_setosa.png\">\n",
    "\n",
    "2.Si, en este caso resulta ser que el ancho del pétalo es menor a 0.8cm, voy a la izquierda y ya terminé: mi planta iris es de la clase setosa.\n",
    "\n",
    "3.Si mi planta no cumple con tener un pétalo de ancho menor a 0.8cm, de nuevo, tengo que moverme al primer nivel de profundidad.\n",
    "\n",
    "<img src=\"./images/iris_tree_versicolor_virginica.png\">\n",
    "El nodo al que llego no es un nodo hoja, sino de decisión, así que dada la condicional , reviso el ancho del pétalo, ¿es menor o igual a 1.75?\n",
    "\n",
    "4.Si el ancho del pétalo fue menor a 1.75 cm voy a la izquierda, clasifico mi planta como versicolor y terminé.\n",
    "<img src=\"./images/iris_tree_versicolor.png\">\n",
    "\n",
    "5.Si por el contrario, el ancho de mi pétalo fue mayor a 1.75cm\n",
    "<img src=\"./images/iris_tree_virginica.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para hacer la predicción *in silico*\n",
    "\n",
    "Vamos a suponer que encontramos una flor con pétalos de 5cm de largo y 1.5cm de ancho, bajo el modelo que estamos viendo debería de corresponder al nodo de profundidad 2 de la izquierda y darnos las siguientes probabilidades: 0 para iris setosa (0/54), .907 para iris versicolor (49/54) y alrededor de .93 para iris virginica (5/54).\n",
    "\n",
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "  Esto quiere decir, ¿cuál es la probabilidad de que la flor que encontre sea de un tipo determinado dado mi árbol de decisión?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf.predict_proba([[5,.15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Por qué sale distinto a nuestra predicción?**\n",
    "\n",
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "  Los árboles de decisión tienen muchas ventajas: son fáciles de usar, fáciles de entender e interpretar, versátiles y poderosos, pero <strong>son muy sensibles al conjunto de entrenamiento</strong> y, al menos scikit learn es estocástico puedes obtenr modelos muy diferentes con el mismo set de datos. A menos que fijes el parámetros random_state.\n",
    "</div>\n",
    "\n",
    "Dado el que sea tan lábil, podemos aprovechar esta propiedad para hacer muchos árboles de decisión y buscar el mejor posible, ese es el principio detrás de RandomForest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chequemos de nuevo sus ventajas y desventajas:\n",
    "\n",
    "#### Ventajas:\n",
    "* Fáciles de explicar\n",
    "* Se ha llegado a decir que son el método que más se parece a las decisiones tomadas por humanos.\n",
    "* Pueden desplegarse gráficamente y explicarse a personas no expertas.\n",
    "* Pueden manejar sin problemas variables cualitativas sin tener que crear variables *dummy*\n",
    "\n",
    "#### Desventajas:\n",
    "* Un árbol por si solo, en genral no tiene el mismo poder predictivo que otros métodos de regresión y clasificación.\n",
    "* Pueden ser muy poco robustos (un pequeño cambio en los datos puede significar un gran cambio en el árbol final)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un ejemplo en Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como siempre antes de empezar a trabajar con Spark inicializamos el Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"decision_tree_classification_example\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sqlContext.read.csv(\"data/iris.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes de aplicar un modelo tenemos que ensamblar nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = ['sepal_length','sepal_width','petal_length','petal_width'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembled = assembler.transform(data)\n",
    "data_VA = assembled.select('features','species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VA.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"species\", outputCol=\"indexedLabel\").fit(data_VA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=3).fit(data_VA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VA.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partir los datos en un conjunto de entrenamiento y uno de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data_VA.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenar el árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxDepth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encadenar los indexadores y el árbol en un Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenar el modelo (árbol de decisión)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hacer predicciones con los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cómo salieron las predicciones de nuestros datos de prueba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Qué tanto se equivoca nuestro predictor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dame sólo un resumen del árbol\n",
    "treeModel = model.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "  Sí se puede hacer la gráfica en Spark pero requiere de evitar usar pipelines y es más complejo: https://github.com/tristaneljed/Decision-Tree-Visualization-Spark/blob/master/DT.py\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora, sí. Vamos con el Random Forest \n",
    "\n",
    "## ¿Qué es Random Forest?\n",
    "\n",
    "Random Forest se basa en el Aprendizaje por Ensamble, que a su vez se inspira en la idea de la \"sabiduría de la multitud\" (wisdom of the crowd).\n",
    "- Si se le pregunta algo complejo a miles de personas al azar ys eagregan sus respuestas, en muchos casos el agregado de las respuestas es mejor que la respuesta de un experto.\n",
    "\n",
    "- Entonces si agregamos las predicciones de un grupo de clasificadores o regresoresen general se obtendrán mejores predicciones que con el mejor predictor individual.\n",
    "\n",
    "**A un grupo de predictores se le denomina un ensamble**\n",
    "\n",
    "De allí viene la idea del aprendizaje por ensamble.\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  Por ejemplo se puede entrenar un grupo de clasisificadores de árboles de decisión, cada uno en un subconjunto aleatorio del conjunto de entrenamiento. Para hacer predicciones, obtendríamos la predicción de cada árbol individual y haríamos la predicción con la clase que obtenga más votos. <strong>A este ensamble de árboles de decisión lo llamamos Random Forest</strong>. \n",
    "</div>\n",
    "\n",
    "<img src=\"./images/random_forest.png\">\n",
    "\n",
    "En los ensambles, se puede usar el mismo algoritmo de entrenamiento como predictor (en este caso árboles de deicisión), pero entrenarlos en differentes subconjuntos aleatorios del conjunto de entrenamiento \n",
    "Dos conceptos útiles:\n",
    "* **Bagging** Es un ensamble con el mismo algoritmo de entrenamiento haciendo muestreo del conjunto de datos de entrenamiento **con reemplazo**. \n",
    "* **Pasting** Es un ensamble con el mismo algoritmo de entrenamiento haciendo muestreo del conjunto de datos de entrenamiento **sin reemplazo**. \n",
    "\n",
    "Cualqueira de estos dos puede usarse para entrenar un random forest, pero es más común utilizar el bagging.\n",
    "\n",
    "Además de para clasificación y regresión, un uso común de Random Forest es medir fácilmente la importancia relativa de cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"],iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"],rnd_clf.feature_importances_):\n",
    "    print(name,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora sí, Random Forest con Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Objetivo\n",
    "Predecir a qué clase pertenece una flor en particular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sqlContext.read.csv('data/iris.csv',inferSchema=True,\n",
    "                     header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describir datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes de aplicar un modelo tenemos que ensamblar nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols = ['sepal_length','sepal_width','petal_length','petal_width'],outputCol='features')\n",
    "\n",
    "assembled = assembler.transform(data)\n",
    "#assembled = assembler.transform(data_ind)\n",
    "data_VA = assembled.select('features','species')\n",
    "\n",
    "data_VA.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform label (species) to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"species\", outputCol=\"indexedLabel\").fit(data_VA)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=3).fit(data_VA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partir los datos en un conjunto de entrenamiento y uno de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data_VA.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenar el modelo de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"species\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Referencias\n",
    "http://www.dmae.upct.es/~mcruiz/Telem06/Teoria/arbol_decision.pdf\n",
    "https://spark.apache.org/docs/2.2.0/mllib-decision-tree.html\n",
    "https://www.analyticsvidhya.com/blog/2015/08/introduction-ensemble-learning/\n",
    "https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#random-forest-classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
